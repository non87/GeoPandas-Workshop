{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "workshop1_colaboratory.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uqt26u4d823q",
        "cuHF6FbB8235",
        "uChV2JpY824w",
        "99qVAbkm825C"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/non87/GeoPandas-Workshop/blob/master/workshop1_colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0PHL7Up823M",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to GeoPandas. Part 1\n",
        "\n",
        "\n",
        "Welcome. This is the first part of the Introduction to GeoPandas Workshop. Strangely enough, today we will not talk about [GeoPandas](https://geopandas.org/ \"GeoPandas\") (gpd) at all. Today, we will be exploring [Pandas](https://pandas.pydata.org/ \"Pandas\"). As the name suggests, GeoPandas crucially depends on Pandas. Pandas is a Python package offering a  convenient way to handle data.  Therefore, a working knowledge of this package is necessary to use GeoPandas. More in general, Pandas is one of the basis of most data analysis pipelines in Python. Therefore, it is useful to know how it works!\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>More Technical:</b> Throughout the notebook. This kind of boxes provide more technical details on what you are seeing. They contain helpful tips, but you can safely skip them the first time you run through the code.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxAgIYDO823N",
        "colab_type": "text"
      },
      "source": [
        "As a first step, we need to import Pandas and Numpy. Here I also make sure that the version of Pandas we are using is up to date. Some of the code I wrote may not work otherwise -- and it is, in general, a good idea to have our package updated when we start a new project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSsoNKqA823O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# It is very common to use numpy and matplotlib along side pandas\n",
        "# We honor this tradition here\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjFgpbgK823S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cUe0j4m823V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This line check the pandas version and it makes sure it is at least 1.0.0\n",
        "version = pd.__version__.split(\".\")\n",
        "print(version)\n",
        "assert int(version[0]) >= 1\n",
        "assert int(version[2]) >= 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FpkzPy5823a",
        "colab_type": "text"
      },
      "source": [
        "### Series\n",
        "\n",
        "Now, that we have importation out of the way, we start the real exploration of Pandas. As mentioned, Pandas helps you handling data. The way it does this is by providing two classes: **Series** and **DataFrame** (note the capitalization).\n",
        "\n",
        "**Series** is the simplest of the two fundamental Pandas classes -- we start from there. Practically, a Series is a unidimensional vector. Series are ordered (like a list), their elements are labeled (like dictionaries) and they have a shape (like a numpy ndarray).\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>numpy:</b> Pandas Series are very similar to unidimensional numpy ndarray. With respect to ndarray, Series have labels as a further way of referencing them.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQTvpIh823b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Series from a list\n",
        "v = [\"He helps Batman\", \"Fights crime in Gotham\", \"Could do whatever, but he helps us\"]\n",
        "ser = pd.Series(v)\n",
        "# A series object has two basic attributes, \"index\" and \"values\".\n",
        "print(f\"This is the value attribute of the Series: {ser.values}\")\n",
        "print(f\"This is the index attribute of the Series: {ser.index}\")\n",
        "# Often, we are also interested into the shape of the Series\n",
        "print(f\"This is the shape attribute of the Series: {ser.shape}\")\n",
        "# To get the number of elements in the Series as a integer\n",
        "print(f\"This is the number of elements in Series: {ser.shape[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpaIZDNQ823d",
        "colab_type": "text"
      },
      "source": [
        "The _index_ attribute contains the labels of the Series elements. In this case, we have not specified the _index_ attribute when we created the Series. This means that Pandas goes to its default and just gives to each element an integer number as a name. We can select elements from the Series by label or by position. At this point, name and position coincides, so we will not see much of a difference, but we will see a difference in a heartbit.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "By default Pandas handles the index through an iterator that generates the labels only once we ask it to -- this is memory efficient. This explains the strange output we saw when we printed the index. If we put the iterator in a list comprehension, we will find out that the names are 0, 1, 2.\n",
        "</div>\n",
        "\n",
        "Labels and positions can be used to access (select) data from the Series. Here, we see for the first time the .loc[ ], .iloc[ ] [operators](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html, \"Selection in Pandas\"). Another fundamental selector -- [ ] -- is used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-889TPaL823d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select by label, with the .loc operator\n",
        "print(f\"This is the element with label 0: {ser.loc[0]}\")\n",
        "# Select by position, with the .iloc operator ('i' stands for integer)\n",
        "print(f\"This is the element at position 0: {ser.iloc[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfMFTRWZ823f",
        "colab_type": "text"
      },
      "source": [
        "With the default configuration, labels and positions for elements coincide, so the difference is subtle. Let's make the difference more visible. In this block, we will see the [ ] operator for the first time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h8lFL5t823g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can directly use the [] operator to select either by name or by position\n",
        "print(f\"Once again, this is the element with position 0: {ser[0]}\")\n",
        "# Change labels\n",
        "ser.index = [\"Robin\", \"Batman\", \"Superman\"]\n",
        "print(f\"This is the new index attribute: {ser.index}\")\n",
        "# Check the new index\n",
        "print(f\"This is the element with label 'Robin': {ser.loc['Robin']}\")\n",
        "# Naturally, changing labels did not change in any way the order of the elements\n",
        "print(f\"This is still the element at position 0: {ser.iloc[0]}\")\n",
        "# Let us check if there is any element with name '0' any more. We will do this we an exception\n",
        "try:\n",
        "    print(f\"This is the element with name 0 in the modified Series: {ser.loc[0]}\")\n",
        "except:\n",
        "    print(\"But no element is labeled 0 anymore.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DUZdZiq823i",
        "colab_type": "text"
      },
      "source": [
        "The [ ] operator can use either labels or positions. For syntactic clarity, I would suggest you stick to .loc[ ] and .iloc[ ] when possible, but (as shown below) this is not always possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVdSKoNa823j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"This is the value of the element with label 'Batman': {ser['Batman']}\")\n",
        "print(f\"This is the value of the element with position 2: {ser[2]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P3CH8cn823m",
        "colab_type": "text"
      },
      "source": [
        "How can we create a Series with a non-default _index_ right from the start?  You can  pass a list of labels as the `index` argument when you create the Series. Alternatively, you can pass a dictionary instead of a list when creating the Series. The keys of the dictionary will become our _index_. As we know, though, dictionary are not ordered. Here, we enforce the order through the [.reindex()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html, \"reindex documentation\") method, which orders the elements of a Series so that the index of the Series follows the order we input.\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>OrderedDict</b>: The OrderedDict class from the standard library package collections provides a way to create a Series with non-default index and fixed order.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34IFRk5F823m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Series with non-default index\n",
        "ser1 = pd.Series(['Terrestrial', 'Terrestrial', 'Kriptonian'], index = ['Robin', 'Batman', 'Superman'])\n",
        "print(f\"This is the index of the new series with the index argument: {ser1.index}\")\n",
        "# Create a Series from a dictionary\n",
        "ser2 = {'Superman': 'Kriptonian', 'Robin': 'Terrestrial', 'Batman': 'Terrestrial'}\n",
        "ser2 = pd.Series(ser2)\n",
        "print(f\"This is the index of the new series from a dictionary: {ser2.index}\")\n",
        "# Order the 2nd series as the first using the .reindex() method.\n",
        "# This makes sure the ser2 present the elements in the same order as ser.\n",
        "ser2 = ser2.reindex(ser.index)\n",
        "print(f\"This is the index of the new series, re-ordered: {ser2.index}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqt26u4d823q",
        "colab_type": "text"
      },
      "source": [
        "#### Selection on Series\n",
        "\n",
        "Now, let us use some more advanced selection. This is the **core** of Pandas, make sure you have it under your belt. \n",
        "\n",
        "We start with selecting more than one element (by position or label) through a list. We check the selection is the same using the Series' method [equals()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.equals.html#pandas.Series.equals, \".equals() Documentation\"), which compares each element (index and value) from a Series to the corresponding element (index and value) from the compared Series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnhxW2nI823r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's select Batman & Robin (notice the order) from the first series both by position and by name\n",
        "labels    = ['Batman', 'Robin']\n",
        "positions = [1,0]\n",
        "# Select by name\n",
        "batman_robin_by_lab = ser.loc[labels]\n",
        "# The output of the selection is another Series.\n",
        "is_series = isinstance(batman_robin_by_lab, pd.Series)\n",
        "print(f\"Is the output a Series? {is_series}\")\n",
        "# Select by position\n",
        "batman_robin_by_pos  = ser.iloc[positions]\n",
        "# Since the output of a multiple selection is a Series, we can use Series methods on it.\n",
        "# Here we use the .equals to check if the selections produced the same output.\n",
        "same = batman_robin_by_lab.equals(batman_robin_by_pos)\n",
        "print(f\"Are selection by positions and labes the same? {same}\")\n",
        "# We take a look at the selection just to see how it looks like!\n",
        "print(batman_robin_by_lab)\n",
        "# Notice, the output Series is ordered differently from the original series.\n",
        "# Selection is indeed another way of reordering a Series.\n",
        "\n",
        "# Both selection strategies would work with the [] operator as well.\n",
        "batman_robin_by_lab = ser[labels]\n",
        "batman_robin_by_pos = ser[positions]\n",
        "# We take a look at the new selection\n",
        "assert batman_robin_by_lab.equals(batman_robin_by_pos)\n",
        "# Identical results, as before!\n",
        "print(batman_robin_by_lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgOffYQL823t",
        "colab_type": "text"
      },
      "source": [
        "Selection with lists is useful, but sometimes we want to just select slices -- which is a position-based way of selecting. Slices only work with the [ ] operator. The syntax for slicing is similar to the syntax for slicing built-in lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mkszaCn823t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First two elements of the series\n",
        "print(f\"Select the first two elements:\\n{ser[:2]}\")\n",
        "# Last two elements of the series\n",
        "print(f\"Select the last two elements:\\n{ser[-2:]}\")\n",
        "# Everything\n",
        "print(f\"Select all elements:\\n{ser[:]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz4SQtHH823w",
        "colab_type": "text"
      },
      "source": [
        "So far, we selected based on positions or labels. Pandas offers ways to select based on **values** . This is powerful because it allows the user to filter data with a very simple sintax without ever writing (slow) for-loops. We will see more of this later. For the moment, let us start from the basis. We want to select only Terrestrial super-heros.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "Selection by value is syntactically and practically very close to 'fancy' indexing in numpy and selection on R dataframes and vectors. \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NRsQ-Nr823x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, notice what happens when we check a series about a condition\n",
        "terrestrial = (ser2 == 'Terrestrial')\n",
        "print(f\"{terrestrial}\\n\")\n",
        "# This is a Series of True/False showing which hero is Terrestrial.\n",
        "# We can use it exactly like a list to select the right super-hero\n",
        "terrestrial_heros = ser[terrestrial]\n",
        "print(f\"{terrestrial_heros}\\n\")\n",
        "# Put everything together in one line\n",
        "terrestrial_heros = ser[ser2 == 'Terrestrial']\n",
        "print(f\"{terrestrial_heros}\\n\")\n",
        "# the .loc[] operator also works here.\n",
        "terrestrial_heros = ser.loc[ser2 == 'Terrestrial']\n",
        "print(f\"{terrestrial_heros}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvRt3Onb823y",
        "colab_type": "text"
      },
      "source": [
        "Value selections can be concatenated with logical operators (and, or, not). These operator have a very specific syntax in Pandas. Parenthesis to establish operators' priority are mandatory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0NVDpRu823z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We introduce a new Series, hp, which quantifies the hit points of our super-heroes\n",
        "hp = pd.Series([1, 2, 100000], index = ['Robin', 'Batman', 'Superman'])\n",
        "# Let's see the operators\n",
        "# not: we want to select non-terrestrial super heros.\n",
        "# We could do the same with the != operator, but I want to show you the syntax\n",
        "non_terr = ser[~(ser2 == 'Terrestrial')]\n",
        "print(f\"{non_terr}\\n\")\n",
        "# And: Terrestrial super-heroes with more than 5 hp\n",
        "hp_hero = ser[(ser2 == 'Terrestrial') & (hp > 5)]\n",
        "# This is an empty Series\n",
        "print(f\"Empty --> {hp_hero}\\n\")\n",
        "#We want someone from planet Heart or someone who has a high resistance\n",
        "everything_goes = ser[(ser2 == 'Terrestrial') | (hp > 500)]\n",
        "print(f\"{everything_goes}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo_lPVDD8231",
        "colab_type": "text"
      },
      "source": [
        "##### Now you, Exercise 1\n",
        "\n",
        "Complete the code to select (1) every value bigger than 1.96 or smaller than -1.96, (2) the first and last position of the Series (this is more difficult)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih1Lk4eR8232",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't worry about these lines of code. They simply draw 100 values from a standard normal distribution. \n",
        "np.random.seed(42)\n",
        "norm = np.random.normal(0,1,100)\n",
        "# Put the normal draws into a Series\n",
        "norm = pd.Series(norm)\n",
        "print(norm.values)\n",
        "\n",
        "# Complete the following two lines\n",
        "\n",
        "# Select values bigger than 1.96 or smaller than -1.96)\n",
        "# bigger_smaller =\n",
        "\n",
        "# first and last element\n",
        "# first_last = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuHF6FbB8235",
        "colab_type": "text"
      },
      "source": [
        "#### Working with Series\n",
        "\n",
        "So far, we have merely selected elements from Series we already created. It is time for us to do something with our data.\n",
        "\n",
        "First, we have to clarify something about datatypes. Every Series has one datatype, which is indeed another important attribute of a Series. Datatypes are like blueprints. Given a datatypes, Pandas will know what operations are allowed (or not) with the data. Pandas has specific datatypes that are more specific than Python's built-in datatypes. Let us check the 5 most important datatypes in Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZYBdNfo8236",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, let's do integer\n",
        "numb = [1, 2, 3]\n",
        "numb = pd.Series(numb)\n",
        "# Pandas will convert the int built-in int type to a int64 type.\n",
        "print(f\"The dtype of the first Series is {numb.dtype}\")\n",
        "# Continue with boolean\n",
        "numb = [1,0,0]\n",
        "# We can specify a dtype when we create a Series\n",
        "# If we don't, in this case we will get int64 as we just saw\n",
        "# We could have create the same Series by passing the list\n",
        "# [True, False, False]\n",
        "numb = pd.Series(numb, dtype = 'boolean')\n",
        "print(f'This is how the second Series looks like:\\n{numb}')\n",
        "print(f'Indeed, the dtype of the second Series is {numb.dtype}')\n",
        "# End with float\n",
        "numb = [0.1, 2.0, 3.4]\n",
        "numb = pd.Series(numb)\n",
        "# Pandas will convert the built-in float type to a float64 type.\n",
        "print(f\"The dtype of the third Series is {numb.dtype}\")\n",
        "# You may have noticed this before. We have so far worked with the 'object' dtype\n",
        "print(f\"The dtype of the ser variable is {ser.dtype}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AgpUlIq8238",
        "colab_type": "text"
      },
      "source": [
        "Objects are the dtypes for things Pandas does not know exactly how to handle. They do not have specific operations you can perform on them. Therefore, it is helpful to bring in a more specific dtype when possible. For the longest time, Series containing strings (like our `ser` Series) necessarily had the `object` dtype. Recently, Pandas introduced the `StringDtype` . \n",
        "\n",
        "This is a good occasion to check how conversions from one dtype to the other work. Let us convert `ser` to a more convenient dtype. While we are here, I will present you the 32-bit version of the `int64` and `float64` types. If you have smallish integer numbers or floats with less than 7 decimal digits, you will be fine with these types. As the names suggest, they occupy half of the space their 64-bit brothers occupy. We will check this with the [.memory_usage()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.memory_usage.html#pandas.Series.memory_usage, \"memory_usage() Documentation\") method.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>int32</b>: an int32 can express (with no loss of precision) any integer number between $-2^{31}$ and $2^{31}-1$. The float8/float16/int8/int16 types are also available if needed. In all these types, the integer number (e.g. 8) stands for the number of bits occupied.\n",
        "</div>\n",
        "\n",
        "You can find more complete information on dtypes: \n",
        "https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#basics-dtypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJxxC0Pu8238",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert ser to a string dtype\n",
        "# As we will see, string has its own operations (unlike object)\n",
        "ser = ser.astype(pd.StringDtype())\n",
        "print(f\"The new dtype for ser is {ser.dtype}\")\n",
        "# Check the memory occupied by numb\n",
        "print(f\"As a {numb.dtype}, numb occupies {numb.memory_usage()} bytes\")\n",
        "# Convert numb to a lighter dtype\n",
        "numb = numb.astype('float32')\n",
        "# Check the memory again\n",
        "print(f\"The new dtype for numb is {numb.dtype}\")\n",
        "print(f\"After conversion to {numb.dtype}, numb occupies {numb.memory_usage()} bytes\")\n",
        "# No information was lost in this conversion.\n",
        "print(f\"In this case, there is no data-loss when converting to float32:\\n{numb}\\n\")\n",
        "# What happens if we conver numb to an integer?\n",
        "numb = numb.astype('int32')\n",
        "# In this case we did have some information loss.\n",
        "print(f\"There is data-loss when converting to integer:\\n{numb}\\n\")\n",
        "# But the memory stays the same\n",
        "print(f\"After conversion to {numb.dtype}, numb still occupies {numb.memory_usage()} bytes\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08mL16YX823_",
        "colab_type": "text"
      },
      "source": [
        "This is to really say that what you can do depends crucially on what you have. Square root of a string? Capitalize an integer? Nah. You have to be aware of what data you are dealing with and, sometimes, convert your data to the right type. In the documentation for each dtype you can explore the kinds of operation they allow. The big difference for us is about scalar VS vectorized operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6YWMeFX823_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When we select elements one by one, the allowed operations depends on the kind of data populating the Series\n",
        "# This is a scalar operation involving just one selected term\n",
        "batman_robin_st = ser.loc['Batman'] + ser.loc['Robin']\n",
        "batman_robin_hp = hp.loc['Batman']  + hp.loc['Robin']\n",
        "print(f'Add string:  {batman_robin_st}')\n",
        "print(f'Add numbers: {batman_robin_hp}')\n",
        "# We can still perform (some) elementwise operation operating directly with Series\n",
        "# These operations are much faster than doing a loop. These are vectorized operations:\n",
        "# you never loop, but still apply a function to all elements.\n",
        "hp_sq   = hp**2\n",
        "ser_len = ser.str.len()\n",
        "print(f'Square the hp:\\n{hp_sq}\\n')\n",
        "print(f'Count the letters in ser:\\n{ser_len}\\n')\n",
        "# Vectorized operation can be used to calculate summary statistics for the entire Series\n",
        "hp_md   = hp.median()\n",
        "hp_mn   = hp.mean()\n",
        "hp_sm   = hp.sum()\n",
        "print(f'The median hp is: {hp_md}')\n",
        "print(f'The mean hp is: {hp_mn}')\n",
        "print(f'The sum of hp is: {hp_sm}')\n",
        "# Finally, vectorized operations can add/ subtract/ etc. two (or more) Series elementwise\n",
        "# In this case elements in the same positions in the two Series will be added/ subtracted/ etc. together\n",
        "double_ser = ser + ser\n",
        "print(f'This is the result of adding ser to itself:\\n{double_ser}\\n')\n",
        "hp_to_hp = (hp/10000)**hp\n",
        "print(f'In his good day, Superman is really invincible: {hp_to_hp}')\n",
        "#Beware of very big numbers or numbers very close to 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM1fqj1m824C",
        "colab_type": "text"
      },
      "source": [
        "If we to change a specific value we use a new selector [.at[ ]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.at.html#pandas.Series.at, \"at[ ] Documentation\"), which only accesses one element at the time. This operator is right choice to change a value inside a Series.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>at[ ]</b>: .at[ ] is faster than .loc[ ]. When setting a value, at[ ] will perform a check on the dtype of the input data and if it is compatible with the dtype of the Series we are modifying. If the data is incompatible, .at[ ] will throw an error. However, when possible .at[ ] silently converts the dtype of the new data you input to match it with the dtype of the Series. This may create confusion when converting from floats to integers -- and possibly other cases. \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPZ_T00E824C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batman just got a new more resistant bat-suit\n",
        "print(f\"Batman had {hp.loc['Batman']} HPs with his old suite.\")\n",
        "hp.at['Batman'] = hp.at['Batman'] + 1\n",
        "print(f\"Now, Batman has {hp.loc['Batman']} HPs. Way to go, Bruce!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNUZLuWK824E",
        "colab_type": "text"
      },
      "source": [
        "More complex operations on the elements of a Series can be handled through looping or through the all important method [.apply( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html#pandas.Series.apply, \".apply() Documentation\"), which applies an input function to every element in the series element-wise. Often, we use .apply( ) with lambda functions or user-defined functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aUz07nA824F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start easy, capitalize descriptions\n",
        "ser_cap = ser.apply(lambda x: x.upper())\n",
        "print(f\"Capitalized:\\n{ser_cap}\\n\")\n",
        "# Do some calculation\n",
        "hp_calc = hp.apply(lambda x: (x**2) - x)\n",
        "print(f\"First calculation:\\n{hp_calc}\\n\")\n",
        "# It is possible to pass arguments as well. Here we pass the positional arg \"n\"\n",
        "hp_calc = hp.apply(lambda x, n: x**2 - n*x, args = [2])\n",
        "print(f\"Second calculation:\\n{hp_calc}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqZnzuqs824G",
        "colab_type": "text"
      },
      "source": [
        "Let's wrap up this part about Series with a more complex example. In this case, we need to apply a different function to each element of the series. Looping is the simplest solution to this issue, but is slower than vectorized operations. \n",
        "\n",
        "To loop, we use the method [.iteritems( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.iteritems.html#pandas.Series.iteritems, \"iteritems Documentation\"), which outputs a tuple with the label of the element we are currently iterating through (0 position) and its value (1 position). \n",
        "\n",
        "I will also show how to solve the problem using (once again) .apply( ). In these cases, .apply( ) tend to be quicker, but it is less memory-efficient. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC_w5OFd824H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Yeah, Superman is all good, but we know he has a weak point: Kriptonite\n",
        "# Lex Luthor decided it is time to inject kriptonite in tap water, but Lex has a scarse supply of Kriptonite.\n",
        "# We model the amount of kriptonite Lex manage to injects in one day as a random number from 0 to 1.\n",
        "# Draw a uniform random numb from 0 to 1.\n",
        "np.random.seed(42)\n",
        "kripto_water = np.random.random()\n",
        "# Round it to the fifth decimal figure\n",
        "kripto_water = np.round_(kripto_water, 5)\n",
        "print(f'Today there is {kripto_water} Kriptonite in the water.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg7QTn3X824I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All super-heroes drink tap water. But the effect of Kriptonite is different depending on where they come from.\n",
        "# We write two functions taking the hp number as input and calculating the hp as effected by kriptonite.\n",
        "\n",
        "# For Superman, below a certain threshold, no effects. Above, the effect are devastating.\n",
        "def kriptonite_effect_superman(x, prop_kript, threshold = 0.7):\n",
        "    if prop_kript >= threshold:\n",
        "        return(x * 0.00001)\n",
        "    else:\n",
        "        return(x)\n",
        "# For Terrestrials, below a certain treshold, the effects are mildly bad. Above, the effects are beneficial.\n",
        "def kriptonite_effect_terrestrial(x, prop_kript, threshold = 0.4):\n",
        "    if prop_kript >= threshold:\n",
        "        return(x * 1.25)\n",
        "    else:\n",
        "        return(x * 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXz2UeZ824M",
        "colab_type": "text"
      },
      "source": [
        "Bad news. We were too optimistic about Superman threshold. After we wrote the function, we discovered his threshold is actually 0.3. We will need to use this value instead of the default value (=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cAW9yPr824M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we want to apply one function to Superman and one function to Batman & Robin\n",
        "# We can easily do this with looping \n",
        "# this can be even done in one line with a list comprehension, but let us be more explicit\n",
        "kripto_hp = []\n",
        "for hero, hp_hero in hp.iteritems():\n",
        "    # We check if the current hero is terrestrial\n",
        "    if ser2[hero] == 'Terrestrial':\n",
        "        kripto_hp.append(kriptonite_effect_terrestrial(hp_hero, kripto_water))\n",
        "    else:\n",
        "        kripto_hp.append(kriptonite_effect_superman(hp_hero, kripto_water, threshold=0.3))\n",
        "kripto_hp = pd.Series(kripto_hp, index = ['Robin', 'Batman', 'Superman'])\n",
        "print(f'The effects of Lex\\'s diabolical plans:\\n{kripto_hp}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRpVVEgA824P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can do this calculation with an .apply() as well. \n",
        "# However, when we use .apply(), the function applied and its argument are the same for all elements in a Series.\n",
        "# In our case we would really like to apply different fuctions to Superman and Terrestrials.\n",
        "# Therefore, we cannot use a single .apply() to do the job...we need a to use .apply() twice\n",
        "# Apply the function for terrestrial. We pass the kripto_water value as a positional argument \n",
        "kripto_t_hp = hp.apply(kriptonite_effect_terrestrial, args = [kripto_water])\n",
        "# Apply the function for Superman. We pass the kripto_water value, but we also modify his treshold with a keyword argument\n",
        "kripto_s_hp = hp.apply(kriptonite_effect_superman, args = [kripto_water], threshold = 0.3)\n",
        "# terr contains whether a super-hero is terrestrial. It is a boolean Series.\n",
        "terr = (ser2 == \"Terrestrial\")\n",
        "# Let's analyze the next line. \n",
        "# we use terr in multiplications since False = 0 and True = 1 when we do arithmetic operation with them.\n",
        "kripto_hp  = (terr * kripto_t_hp) +( ~(terr) * kripto_s_hp)\n",
        "# Overall, we get the same result\n",
        "print(f'Once again, the effects of Lex\\'s diabolical plans:\\n{kripto_hp}\\n')\n",
        "# No loop (= faster), but extra calculation, lines and memory."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNkwqjw2824R",
        "colab_type": "text"
      },
      "source": [
        "##### Your Turn\n",
        "\n",
        "Start from a list containing numbers in string formats (this happens if you read numbers from a file or scrape them from the web). Calculate the median of the values. Use the [np.round()](https://numpy.org/doc/stable/reference/generated/numpy.round_.html) function to get the closest integer. (More difficult) If the closest integer is even, square the number. If the closest integer is odd, multiply the number by 2.\n",
        "\n",
        "Example of np.round: np.round(2.3) will output 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDQn43aB824S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initial list\n",
        "numb = ['1.2', '1.1', '0.2', '2.8', '7.1', '5.5', '6.7']\n",
        "# Put them into a Series\n",
        "numb = pd.Series(numb)\n",
        "print(f'Is numb a Series? {isinstance(numb, pd.Series)}')\n",
        "\n",
        "# Change their dtype to float32\n",
        "# numb = ...\n",
        "# Calculate the median\n",
        "# med = ...\n",
        "\n",
        "# Use .apply() and np.round() to round number.\n",
        "# rounded_numb = ...\n",
        "\n",
        "# Give your best try. square numbers that are close to an even\n",
        "# multiply by 2 those numbers that are close to an odd.\n",
        "# Suggestion to check if a number (x) is odd or even: x%2 == 0\n",
        "# But for % to work the number has to be of the integer type\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpJjUHDi824U",
        "colab_type": "text"
      },
      "source": [
        "### DataFrame\n",
        "\n",
        "You may have noticed that we have three inter-related variables (ser, ser2 and hp). All of these variables are Series with the same index. The logical next step is to put the three series in a one table, where each row represents a hero and each column represents a characteristic of the hero (such as hp). This is the intution behind the **DataFrame** object. A DataFrame is the way Pandas represents tabular data. Every row represents an entity. Every column represents a characteristic. Beware, DataFrames are still made of Series: as the code below shows, every column is a Series. As shown below, we can also interpret evey row as a Series. Therefore, what we learned about Series will be very relevant.\n",
        "\n",
        "The major difference between a Series and a DataFrame regards the number of dimensions of the two objects. Whereas a Series is a unidimensional vector, a DataFrame is a bi-dimensional table -- a.k.a. a matrix or a spreadsheet, if you prefer these terms. Like Series, a DataFrame is ordered (in both dimensions), its elements are labeled (in both dimension) and it has a shape. What I mean by \"in both dimensions\" is that we have an order among rows as well an order among columns. Similarly, both the rows and the columns have labels. \n",
        "\n",
        "Like Series, a DataFrame has an _index_ , a _shape_ , some _values_ , assigned _dtypes_ . Moreover it also presents a _columns_ attribute containing the names of the columns.\n",
        "\n",
        "We use the DataFrame's method [.head( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html?highlight=head, \".head( ) Documentation\"), which prints for us the first 5 rows of our data -- in this case, it will only print 3 rows since our data is that small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4FXQvh4824U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a DataFrame from the Series we have above\n",
        "super_df = pd.DataFrame({'Description': ser, 'Origin': ser2, 'HP':hp})\n",
        "super_df.head()\n",
        "# Back to some old friends\n",
        "print(f'This is the index attribute of the dataframe: {super_df.index}\\n')\n",
        "print(f'This is the shape attribute of the dataframe: {super_df.shape}\\n')\n",
        "# The values of a df is a 2-dimensional numpy.ndarray\n",
        "print(f'This is the values attribute of the dataframe:\\n{super_df.values}\\n')\n",
        "# Notice the s!\n",
        "print(f'This is the dtypes attribute of the dataframe:\\n{super_df.dtypes}\\n')\n",
        "# This is new. It is like an index, but for columns\n",
        "print(f'This is the columns attribute of the dataframe:\\n{super_df.columns}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4ChRvP4824W",
        "colab_type": "text"
      },
      "source": [
        "#### Exploratory Data Analysis with DataFrame\n",
        "\n",
        "You may have guessed that most of the time we will not be inputing the data by hand. Pandas can read tabular data (.csv, .tsv, Excel) that you have stored in the hard drive (or on a server). For the rest of the workshop, we will use the [super hero dataset](https://www.kaggle.com/claudiodavi/superhero-set), originally published on Kaggle by Claudio Davi. It is in the same repository as this notebook and you should have downloaded it alongside this file. We use the command [read_csv( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html, 'read_csv( ) Documentation') to read the dataset as a DataFrame in our environment.\n",
        " \n",
        "<div class=\"alert alert-block alert-success\"><b>read_csv( )</b>: read_csv( ) is one of the most complex command in Pandas for the amount of different file formats it handles (on every OS!) as well as the great amount of options that it offers. Among all options, I would like to signal the dialect option to control non-standard format for tabular data (like tab-separated values). Another important set of options are the nrows, usecols and chunksize that allow users to deal with data that cannot fit in the RAM.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_D4EwnU824X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use the url as a path.\n",
        "# Normally you would pass a path from your HD.\n",
        "url = r'https://raw.githubusercontent.com/non87/GeoPandas-Workshop/master/data/heroes_information.csv'\n",
        "super_df = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fO_lYir824Y",
        "colab_type": "text"
      },
      "source": [
        "Now, everytime I load a dataset for the first time, I do a routine check of what I am seeing. I use the .head( ) method seen above, then the [.info( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info, \".info( ) Documentation\") method. As the name suggests, .info( ) gives you a lot of important information about the DataFrame: the `dtype` of each column (remember, every column is a Series), the memory occupied by the DataFrame, the _index_ of the DataFrame and the number of NaNs -- but more on NaNs in a minute.\n",
        "\n",
        "Another important exploratory step is to print summary statistics for each variable. We will use the [.describe( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html, \".describe( ) Documentation\") method to output summary statistics of each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwyxglz0824Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Head: {super_df.head()}')\n",
        "print(\"###\")\n",
        "print(f'{super_df.info()}')\n",
        "print(\"###\")\n",
        "# Notice the include=all. Otherwise, you will get only the description of numerical column\n",
        "print(super_df.describe(include='all'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt2bknnW824c",
        "colab_type": "text"
      },
      "source": [
        "Notice that we have the same problem as above, we have many `object` dtypes where we really would like `string`. This is a quick trick to convert all `object` columns using the method [.convert_dtypes( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.convert_dtypes.html?highlight=convert_dtypes#pandas.DataFrame.convert_dtypes, \".convert_dtypes( ) Documentation\"). Another possibility would be to use the `category` dtype, but let us stick to `string`.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">By default, .convert_dtypes( ) will also convert integers and booleans to corresponding types supporting the new pd.NA null value. As long as you will not run into a NaN these conversion should be hardly noticeable. However, we avoid it here because it creates problems with the plotting below.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJSPO2In824d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "super_df = super_df.convert_dtypes(convert_integer = False)\n",
        "print(f\"With new dtypes:\\n{super_df.info()}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FKUpLH0824f",
        "colab_type": "text"
      },
      "source": [
        "You may have noticed that the info command told us there are 0 NaNs. Great! But wait, what does it mean that Abraxas weights -99 Kgs? My understanding is that -99 is the way that the data collector coded NaNs. The .info( ) commands only recognizes as NaN those values that are \"ufficially\" coded as NaNs by Pandas. You create those with specific commands we will see in a bit. The .describe( ) method indeed shows that we have -99 as minimum values in the `Height` and `Weight` columns.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\"><b>Missing data( )</b>: The way missing data is coded internal to Pandas is a little bit of jungle. Few different types of NaN exist depending on the dtype and the situation is evolving. You can check the following link for a complete and updated overview: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data-na </div>\n",
        "\n",
        "Before proceeding, I need to spell out a difference in the way the [ ] selector works on a DataFrame with respect to Series. With a DataFrame, this selector is only used to retrieve entire columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxoZnfgq824f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example\n",
        "print(f\"This is the name column: {super_df['name']}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIuKEzDf824h",
        "colab_type": "text"
      },
      "source": [
        "A quick, alternative way to check the state of our data is plotting. We will plot the weight and height variables. Pandas has convenient commands that make quick plotting very easy. These are rough plots for exploratory analysis. For \"publication-level\" plots, we will always use matplotlib, which is what Pandas uses internally anyway. This is outside the scope of the workshop, but Pandas dialogues with matplotlib very well. For more info on plotting in Pandas, follow this [link](https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html#04_plotting, \"Plotting in Pandas\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYJflaX6824h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "super_df['Height'].hist(bins=50)\n",
        "# Just to reset matplotlib figure.\n",
        "# If you don't do this, the 2 histograms will end up in the same picture\n",
        "plt.figure()\n",
        "super_df['Weight'].hist(bins=50)\n",
        "# It appears there is a number of heros with -99 height and weight.\n",
        "# But, are those the same heros?\n",
        "plt.figure()\n",
        "super_df.plot.scatter(x='Height', y='Weight')\n",
        "# Just FYI you can't as easily plot categorical data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlJm8Fx3824j",
        "colab_type": "text"
      },
      "source": [
        "It looks like we want to substitute some values (-99) with NAs. Let's do this by putting these values equal to `None`, which Pandas recognize as a code for NaN -- other codes are available. \n",
        "\n",
        "This is a typical case where selection helps (there are other workarounds, but selection is the way we will do it). Lucky enough, we know how to select from our work with Series. So, selection in DataFrame will be way quicker. As for Series, a selection can be based on position, label or values. We will use our friends .iloc[ ] and .loc[ ] for selections on positions and labels, respectively. The key difference between Series and DataFrame when selecting is that in a DataFrame you have to select *2* dimensions. You have a selection for the row and a seletion for the column. When you select on both rows and columns by label/position, you must use the same kind of selection (label or position) for both dimensions. Selection by value is more flexible. It is done with .loc[ ] and it typically mixes a value selection for row and a label-selection for columns (see examples below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FYyGbOZ3824j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We already saw that the .[] operator selects entire columns.\n",
        "# This is an example of .iloc[ ] on rows: select first five rows \n",
        "# notice the , to separate the selection on rows from the selection on columns\n",
        "print(f'This is the same as .head( ):\\n{super_df.iloc[:5, :]}\\n')\n",
        "# Select second and fifth columns\n",
        "print(f'These are the second and fifth columns:\\n{super_df.iloc[:,[1,4]]}')\n",
        "# Select same column, but through their labels\n",
        "print(f\"These are really the same columns:\\n{super_df.loc[:, ['name', 'Race']]}\")\n",
        "# This is a selection of rows and columns by index. Notice that index is the default integer list...\n",
        "print(f\"Some random heroes:\\n{super_df.loc[[231,422, 455], ['name', 'Race']]}\")\n",
        "# Selection of rows and columns by value: we use the .loc[ ] operator\n",
        "# Under the hood, the .loc[ ] operator accepts Boolean Series as selector\n",
        "# It is the same mechanism we saw for selecting Series based on values\n",
        "print(f\"Say -99:\\n {super_df.loc[super_df['Height'] == -99, ['name', 'Height', 'Weight']]}\")\n",
        "# Substitute all -99 with None\n",
        "super_df.loc[super_df['Height'] == -99, 'Height'] = None\n",
        "super_df.loc[super_df['Weight'] == -99, 'Weight'] = None\n",
        "# Indeed, This is now empty\n",
        "print(f\"Say -99 no more!\\n {super_df.loc[super_df['Height'] == -99, ['name', 'Height']]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-p-ZzR1824l",
        "colab_type": "text"
      },
      "source": [
        "You may have noticed that the columns 'Race' and 'Hair-color' contain a lot of \"-\". Even the columns 'Gender', 'Eye color', and 'Alignment' contains some \"-\". Let's set all those \"-\" to NaN as well.  When it comes to the `string` dtype, we need to use a slightly different command to create NaNs. This is another novelty of Pandas 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HSju4iR824m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create NaNs in the 'Gender' column\n",
        "super_df.loc[super_df['Gender'] == '-', 'Gender'] = pd.NA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr_jb9O0824o",
        "colab_type": "text"
      },
      "source": [
        "##### Your Turn\n",
        "\n",
        "Set the rest of the \"-\" to NaNs. To make sure we don't mess up the data (it happens!), we will do the exercise on a copy of the DataFrame first. We will use the method [.copy( )](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html?highlight=copy#pandas.DataFrame.copy, '.copy( ) Documentation') to create such a copy.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\"><b>SerenDEEPity</b>: By default, .copy( ) will create a shallow copy of a DataFrame. This is sufficient 99% of the time. You can set the keyword argument 'deep=True' when calling the method to obtain a deep copy. As the documentation explains, this is still not as deep as the deepcopy created by the deepcopy function from the copy package. You can use this function if you want to be extrasafe about not modifying the copied object.</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t24-lplK824o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mistakes happen. We will use a copy of the DataFrame for this exercise\n",
        "playground = super_df.copy()\n",
        "# Really the same\n",
        "print(playground.head())\n",
        "# For each column in the list cols, change '-' to Nan in the playground df\n",
        "cols = ['Eye color', 'Race', 'Hair color', 'Skin color', 'Alignment']\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOoA4BWs824s",
        "colab_type": "text"
      },
      "source": [
        "You may wonder whether it is possible to do this with a loop..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln7Xxb37824t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in cols:\n",
        "    super_df.loc[super_df[col] == '-', col] = pd.NA\n",
        "print(super_df.info())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkXMZRCn824u",
        "colab_type": "text"
      },
      "source": [
        "Especially for 'Skin color' we have only 10% of non NaN. This may be a little too much. If you check heroes like Superman, Batman or Black Panther you will soon realize that \"Skin color\" only registers exotic skin colors (like blue or green), but no human colors. We should remedy this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWxmSM4M824v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's remedy the excessive amount of NaNs\n",
        "super_df.loc[super_df['Race']=='Human', 'Skin color'] ='human-like'\n",
        "print(f\"{super_df.loc[:,['name', 'Race', 'Skin color']].head()}\\n\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uChV2JpY824w",
        "colab_type": "text"
      },
      "source": [
        "#### Working with DataFrames\n",
        "\n",
        "To wrap this up, we will answer the question that keep most of us awake at night: How does the Body Mass Index (BMI) of Marvel heroes compare to the BMI of DC heroes? In answering this all important question, we will check how to modify/ create data for and from a DataFrame.\n",
        "\n",
        "Let's start with creating our own index for the data. You may have notice a column named \"Unnamed: 0\". This was the original index column in the data. We can signal this to Pandas when loading the data -- but we did not know before opening the data! Anyway, we will create an index from the information in each row using the [.iterrows()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html?highlight=iterrows#pandas.DataFrame.iterrows, \".iterrows( ) Documentation\") method. It is substantially similar to the .iteritems() method from Series, in that it outputs a tuple where the first element is the index of the row and the second element is the content of the row...in the form of a Series!\n",
        "\n",
        "To change index we will use the method [.set_index( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html#pandas.DataFrame.set_index, '.set_index( ) Documentation'). This is probably a good time to mention that Pandas has a specific kind of object to represent an Index for a Series or a DataFrame. This kind of object is called [Index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.html?highlight=index#pandas.Index, \"Index documentation\"). It is substantially an unmutable numpy ndarray. This is really nothing to be concerned about too much, but we need to be aware of this when setting a new index for the DataFrame -- see the code.\n",
        "\n",
        "We will create a index in the form \"publisher_integer\", where integer is a running count of how many heroes any publisher produced. There are many ways to do this. In the space of a single loop we can use a [Counter](https://docs.python.org/3.6/library/collections.html#collections.Counter, \"Counter Documentation\") dictionary from collections. Also, Counters are great, so it is good to know they exist.\n",
        "\n",
        "Finally, we will drop the not-so-interesting \"Unnamed: 0\" column with the method [.drop( )](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop, \".drop( ) Documentation\"), which, as the name suggests, is used to drop columns or rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1hChrd8824x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Just to show you how .iterrows() works, I will print out the first element out of the loop.\n",
        "iterrows_check = super_df.iterrows()\n",
        "ind, row = next(iterrows_check)\n",
        "print(f\"This is the first element in the tuple, that is the index: {ind}\\n\")\n",
        "print(f\"This is the second element in the tuple, that is the row as a Series:\\n{row}\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXG7P1Zb8244",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Counter\n",
        "from collections import Counter\n",
        "# Dictionary Counter for the publishers\n",
        "pub_count  = Counter()\n",
        "# List that will contain the new indices\n",
        "ind_column = []\n",
        "\n",
        "\n",
        "# We will now use iterrows to create an index column.\n",
        "for ind, row in super_df.iterrows():\n",
        "    # we need to check for NA in the publisher part\n",
        "    if row.loc['Publisher'] is pd.NA:\n",
        "        # Notice that we are not really changing the value in the DataFrame, but only in row.\n",
        "        row.loc['Publisher'] = 'unknown'\n",
        "    # Since row is a Series, we use what we know about Series to select data \n",
        "    # We delete white spaces from the publisher name using the .replace() method of strings\n",
        "    pub_name = row.loc['Publisher'].replace(\" \", \"\")\n",
        "    # We ask how many heroes from the same publisher we already saw to our Counter\n",
        "    # Notice that a Counter will always output 0 when asked about a key it does not already have\n",
        "    pub_n = pub_count[row.loc['Publisher']]\n",
        "    # We construct the new index from the publisher name and the publisher n\n",
        "    new_ind = pub_name  + '_' + str(pub_n)\n",
        "    # Append the index\n",
        "    ind_column.append(new_ind)\n",
        "    # Update the counter\n",
        "    pub_count[row.loc['Publisher']] += 1\n",
        "\n",
        "# Now change index.\n",
        "# We have to conver the list to a Index object.\n",
        "super_df = super_df.set_index(pd.Index(ind_column))\n",
        "# Drop the 'Unnamed: 0' columns\n",
        "super_df = super_df.drop(labels = ['Unnamed: 0'], axis = 1)\n",
        "# Looks better\n",
        "print(f\"New index:\\n{super_df.head()}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G02JsYjY8249",
        "colab_type": "text"
      },
      "source": [
        "Now that our df looks better, let's focus on the real question. Is there difference in the BMI of heroes from Marvel and from DC?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j75sX8P58249",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the BMI of the heroes\n",
        "super_df['BMI'] = super_df['Weight']/((super_df['Height']/100)**2)\n",
        "# No questions, heroes have a lot of different bodies.\n",
        "print(super_df.loc[super_df['BMI'].notna()].head())\n",
        "# But now back to the real question\n",
        "# We will evaluate this using the median. Other choices could be reasonable.\n",
        "# Notice that the median automatically ignores NaNs\n",
        "marvel_med = super_df.loc[super_df['Publisher'] == 'Marvel Comics', 'BMI'].median()\n",
        "DC_med = super_df.loc[super_df['Publisher'] == 'DC Comics', 'BMI'].median()\n",
        "print(f\"This is the median for Marvel: {marvel_med}\")\n",
        "print(f\"This is the median for DC: {DC_med}\")\n",
        "print(f\"And this is their difference: {marvel_med - DC_med}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99qVAbkm825C",
        "colab_type": "text"
      },
      "source": [
        "#### Now You, but for Real\n",
        "\n",
        "This workshop introduced the foundation of Pandas: Series, DataFrames, Dtypes, vectorized operations and selection. There is a lot more ground to cover, but the foundations you learned here will *always* come up in your use of Pandas.  Real life coding is a body-to-body with documentation: very few coders can do without looking at online documentation frequently. This workshop has put you in a place where you can use Pandas documentation and make sense of what is going on (most of the time).\n",
        "\n",
        "So, let's simulate real coding in this controlled environment. In the next exercise you will probably need to use methods and functions that were not introduced in this workshop. Use Google and the remarkably-complete official [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/index.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvRTD514825D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are sort of open-ended questions, meaning that I did not provide you a straightforward way to do them\n",
        "# 1. Find out which heros have the maximum and minimum BMI overall\n",
        "\n",
        "# Try use the method .groupby( ) for the following. But other solutions are available if you prefer.\n",
        "# 2. Check the minimum BMI for all publishers.\n",
        "# 3. Check the maximum BMI for all publishers.\n",
        "# The range of a variable is the maximum value minus the minimum value.\n",
        "# 4. Find out which publisher has the widest range. \n",
        "\n",
        "# 5. Check the mean BMI for all publishers excluding those that only have 1 hero."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}